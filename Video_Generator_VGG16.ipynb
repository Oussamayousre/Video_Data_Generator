{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Video_Generator_VGG16_(3)_(1) (2).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCkVdSIFsBzZ",
        "outputId": "af2ddc69-833a-41c4-b531-110c390a2957"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5vsPabo-Ipm"
      },
      "source": [
        "### in this part of code , i will train a VGG16 model on faces detected in the frames , using Dlib\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAQHJsmhtgbe"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets ,layers,models\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.keras.applications import *\n",
        "import dlib\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import os \n",
        "import cv2\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.utils import Sequence\n",
        "# i used a keras model , so i have to use data_utils.Sequence\n",
        "from keras.utils import data_utils\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtaqNSlij8hg"
      },
      "source": [
        "detector = dlib.get_frontal_face_detector()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAuQij6WqaHX",
        "outputId": "02f27ffb-57ad-492e-9a63-ee68b8cbedf7"
      },
      "source": [
        "!wget http://dlib.net/files/mmod_human_face_detector.dat.bz2\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-16 21:03:00--  http://dlib.net/files/mmod_human_face_detector.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 694709 (678K)\n",
            "Saving to: ‘mmod_human_face_detector.dat.bz2.1’\n",
            "\n",
            "mmod_human_face_det 100%[===================>] 678.43K  1.60MB/s    in 0.4s    \n",
            "\n",
            "2021-08-16 21:03:00 (1.60 MB/s) - ‘mmod_human_face_detector.dat.bz2.1’ saved [694709/694709]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB8FeubVqcKo",
        "outputId": "cee91cac-79de-4081-8918-d4e7494b7ce6"
      },
      "source": [
        "!bunzip2 /content/mmod_human_face_detector.dat.bz2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bunzip2: Output file /content/mmod_human_face_detector.dat already exists.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyw2rfHTrJwL"
      },
      "source": [
        "cnn_face_detector = dlib.cnn_face_detection_model_v1('/content/mmod_human_face_detector.dat')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_6Iy1HDsFDa"
      },
      "source": [
        "#next step is to collect all the videos in one folder and take the first character of their name which is the label \n",
        "import numpy as np\n",
        "import keras\n",
        "#path to video's folder\n",
        "path = '/content/gdrive/MyDrive/variables/Fold2_part2'\n",
        "#\n",
        "train_ID = os.listdir(path)[1:]\n",
        "class VideoFrameGenerator(data_utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self,train_ID, batch_size=1, dim=(64,64), shuffle=True ):\n",
        "        'Initialization'\n",
        "        self.batch_size = batch_size\n",
        "        self.train_ID = train_ID   \n",
        "        self.shuffle = shuffle\n",
        "        self.dim = dim\n",
        "        self.on_epoch_end()\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.train_ID) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.train_ID[k] for k in indexes]\n",
        "        #list_IDs_temp = [20]\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "        X =  np.array([X])[0]\n",
        "        y =  np.array([y])\n",
        "        y = y.reshape(y.shape[1])\n",
        "        randomize = np.arange(y.shape[0])\n",
        "        np.random.shuffle(randomize)\n",
        "        X = X[randomize]\n",
        "        y = y[randomize]\n",
        "        return X , y \n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.train_ID))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        #X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        #y = np.empty((self.batch_size), dtype=int)\n",
        "        arr_1 = os.listdir(f'/content/gdrive/MyDrive/variables/Fold2_part2/{list_IDs_temp[0]}')\n",
        "        path_1  = f'/content/gdrive/MyDrive/variables/Fold2_part2/{list_IDs_temp[0]}'\n",
        "        isDirectory = os.path.isdir(path_1)\n",
        "        if isDirectory : \n",
        "          label_train  = []\n",
        "          Frame_train = [] \n",
        "          # Generate data\n",
        "          for path_3 in arr_1 :  \n",
        "            if path_3 != '.ipynb_checkpoints' : \n",
        "                       \n",
        "              label = int(os.path.splitext(path_3)[0])\n",
        "              full_path_2 = f\"/content/gdrive/MyDrive/variables/Fold2_part2/{list_IDs_temp[0]}/{path_3}\"\n",
        "              vs = cv2.VideoCapture(full_path_2)\n",
        "              nb_frame = 0\n",
        "              while True :\n",
        "                ret, image = vs.read() \n",
        "                if ret == False  or nb_frame == 5000 : \n",
        "                    break\n",
        "                #rects = detector(image,0)\n",
        "                rects = detector(image, 0)\n",
        "                for face in rects:                          \n",
        "                  x1 = face.left() # left point\n",
        "                  y1 = face.top() # top point\n",
        "                  x2 = face.right() # right point\n",
        "                  y2 = face.bottom() # bottom point\n",
        "                  img = image[y1:y2,x1:x2]              \n",
        "                  if img.size != 0 :\n",
        "                    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "                    img = cv2.resize(image, self.dim)\n",
        "                    #image = image.img_to_array(image)\n",
        "                    label_train.append(label)\n",
        "                    Frame_train.append(img)\n",
        "                    nb_frame += 1\n",
        "              vs.release()\n",
        "              cv2.destroyAllWindows()\n",
        "        \n",
        "        return Frame_train, label_train\n",
        "     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjNoXriOs7hy"
      },
      "source": [
        "path = '/content/gdrive/MyDrive/variables/Fold2_part2'\n",
        "train_ID = os.listdir(path)[1:]\n",
        "\n",
        "# Parameters\n",
        "params = {'dim': (64,64),\n",
        "          'batch_size': 1,\n",
        "          'shuffle': True}\n",
        "training_generator = VideoFrameGenerator(train_ID, **params)\n",
        "validation_generator = VideoFrameGenerator([train_ID[0]], **params)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63TCHBtYx-ib"
      },
      "source": [
        "x ,y = training_generator.__getitem__(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9sv70WnyIH_",
        "outputId": "f641ea42-6985-41d5-9185-44270f5b548f"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 64, 64, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFJ6wrnWtVzs"
      },
      "source": [
        "vgg16 = VGG16( include_top=False, input_shape = (64,64, 3) , weights = 'imagenet' )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7QD9TxmuCY4"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "for layer in vgg16.layers[:-1]: # this is where I changed your code\n",
        "    model.add(layer)    \n",
        "# Freeze the layers \n",
        "#for layer in model.layers:\n",
        "#    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA1e7TyTvdZc"
      },
      "source": [
        "model.add(Flatten())\n",
        "model.add(Dense(11, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BglYwwmCvj7i",
        "outputId": "7720cccb-46cd-495c-f04a-ff4c8b572edf"
      },
      "source": [
        "model.build((0,64,64,3))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 11)                90123     \n",
            "=================================================================\n",
            "Total params: 14,804,811\n",
            "Trainable params: 14,804,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOrzHjfHvlM4"
      },
      "source": [
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "model.compile(optimizer = opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "L197gOUavvvD",
        "outputId": "543b3549-e592-4e73-d695-bb87eeb0cda7"
      },
      "source": [
        "# try to capture face then train the model on faces directly\n",
        "history = model.fit(training_generator, validation_data=validation_generator, epochs = 10 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMkwpt15LJlz"
      },
      "source": [
        "model.save('/content/gdrive/MyDrive/variables')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHVMrv3I-Ygd"
      },
      "source": [
        "### in this part of code , i will train the VGG16 model on the whole frame without detecting the faces , it may be faster , but not accurate enough \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuEB5eJ4-ihr"
      },
      "source": [
        "\"\"\"#next step is to collect all the videos in one folder and take the first character of their name which is the label \n",
        "import numpy as np\n",
        "import keras\n",
        "#path to video's folder\n",
        "path = '/content/gdrive/MyDrive/variables/Fold2_part2'\n",
        "#\n",
        "train_ID = os.listdir(path)[1:]\n",
        "class VideoFrameGenerator(data_utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self,train_ID, batch_size=1, dim=(64,64), shuffle=True ):\n",
        "        'Initialization'\n",
        "        self.batch_size = batch_size\n",
        "        self.train_ID = train_ID   \n",
        "        self.shuffle = shuffle\n",
        "        self.dim = dim\n",
        "        self.on_epoch_end()\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.train_ID) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.train_ID[k] for k in indexes]\n",
        "        #list_IDs_temp = [20]\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "        X =  np.array([X])[0]\n",
        "        y =  np.array([y])\n",
        "        y = y.reshape(y.shape[1])\n",
        "        randomize = np.arange(y.shape[0])\n",
        "        np.random.shuffle(randomize)\n",
        "        X = X[randomize]\n",
        "        y = y[randomize]\n",
        "        return X , y \n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.train_ID))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        #X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        #y = np.empty((self.batch_size), dtype=int)\n",
        "        arr_1 = os.listdir(f'/content/gdrive/MyDrive/variables/Fold2_part2/{list_IDs_temp[0]}')\n",
        "        path_1  = f'/content/gdrive/MyDrive/variables/Fold2_part2/{list_IDs_temp[0]}'\n",
        "        isDirectory = os.path.isdir(path_1)\n",
        "        if isDirectory : \n",
        "          label_train  = []\n",
        "          Frame_train = [] \n",
        "          # Generate data\n",
        "          for path_3 in arr_1 :  \n",
        "            if path_3 != '.ipynb_checkpoints' :             \n",
        "              label = int(os.path.splitext(path_3)[0])\n",
        "              full_path_2 = f\"/content/gdrive/MyDrive/variables/Fold2_part2/{list_IDs_temp[0]}/{path_3}\"\n",
        "              vs = cv2.VideoCapture(full_path_2)\n",
        "              nb_frame = 0\n",
        "              while True :\n",
        "                ret, image = vs.read() \n",
        "                if ret == False  or nb_frame == 500: \n",
        "                    break\n",
        "                img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "                img = cv2.resize(image, self.dim)\n",
        "                #image = image.img_to_array(image)\n",
        "                label_train.append(label)\n",
        "                Frame_train.append(img)\n",
        "                nb_frame += 1\n",
        "              vs.release()\n",
        "              cv2.destroyAllWindows()\n",
        "        \n",
        "        return Frame_train, label_train\n",
        "     \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeICD-pdvzlz"
      },
      "source": [
        "path = '/content/gdrive/MyDrive/variables/Fold2_part2'\n",
        "folder_ID = os.listdir(path)\n",
        "train_ID = folder_ID[1:]\n",
        "def gen_frames(index ,train = True): \n",
        "  if train : \n",
        "    arr_1 = os.listdir(f'/content/gdrive/MyDrive/variables/Fold2_part2/{train_ID[index]}')\n",
        "    path_1  = f'/content/gdrive/MyDrive/variables/Fold2_part2/{train_ID[index]}'\n",
        "    isDirectory = os.path.isdir(path_1)\n",
        "    if isDirectory : \n",
        "      label_train  = []\n",
        "      Frame_train = [] \n",
        "      # Generate data\n",
        "      for path_3 in arr_1 :  \n",
        "        if path_3 != '.ipynb_checkpoints' :             \n",
        "          label = int(os.path.splitext(path_3)[0])\n",
        "          full_path_2 = f\"/content/gdrive/MyDrive/variables/Fold2_part2/{train_ID[index]}/{path_3}\"\n",
        "          vs = cv2.VideoCapture(full_path_2)\n",
        "          nb_frame = 0\n",
        "          while True :\n",
        "            ret, image = vs.read() \n",
        "            if ret == False  or nb_frame == 10000: \n",
        "                break\n",
        "            img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            img = cv2.resize(image, (64,64))\n",
        "            #image = image.img_to_array(image)\n",
        "            label_train.append(label)\n",
        "            Frame_train.append(img)\n",
        "            nb_frame += 1\n",
        "          vs.release()\n",
        "          cv2.destroyAllWindows()\n",
        "      X =  np.array([Frame_train])[0]\n",
        "      y =  np.array([label_train])\n",
        "      y = y.reshape(y.shape[1])\n",
        "      randomize = np.arange(y.shape[0])\n",
        "      np.random.shuffle(randomize)\n",
        "      X = X[randomize]\n",
        "      y = y[randomize]\n",
        "      return X, y\n",
        "  else :\n",
        "    arr_1 = os.listdir(f'/content/gdrive/MyDrive/variables/Fold2_part2/{folder_ID[0]}')\n",
        "    path_1  = f'/content/gdrive/MyDrive/variables/Fold2_part2/{folder_ID[0]}'\n",
        "    isDirectory = os.path.isdir(path_1)\n",
        "    if isDirectory : \n",
        "      label_train  = []\n",
        "      Frame_train = [] \n",
        "      # Generate data\n",
        "      for path_3 in arr_1 :  \n",
        "        if path_3 != '.ipynb_checkpoints' :             \n",
        "          label = int(os.path.splitext(path_3)[0])\n",
        "          full_path_2 = f\"/content/gdrive/MyDrive/variables/Fold2_part2/{folder_ID[0]}/{path_3}\"\n",
        "          vs = cv2.VideoCapture(full_path_2)\n",
        "          nb_frame = 0\n",
        "          while True :\n",
        "            ret, image = vs.read() \n",
        "            if ret == False  or nb_frame == 10000: \n",
        "                break\n",
        "            img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            img = cv2.resize(image, (64,64))\n",
        "            #image = image.img_to_array(image)\n",
        "            label_train.append(label)\n",
        "            Frame_train.append(img)\n",
        "            nb_frame += 1\n",
        "          vs.release()\n",
        "          cv2.destroyAllWindows()\n",
        "    X =  np.array([Frame_train])[0]\n",
        "    y =  np.array([label_train])\n",
        "    y = y.reshape(y.shape[1])\n",
        "    randomize = np.arange(y.shape[0])\n",
        "    np.random.shuffle(randomize)\n",
        "    X = X[randomize]\n",
        "    y = y[randomize]\n",
        "    return X, y\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9CVFTlW-3Uz"
      },
      "source": [
        "path = '/content/gdrive/MyDrive/variables/Fold2_part2'\n",
        "train_ID = os.listdir(path)[1:]\n",
        "folder_index = 0\n",
        "# Parameters\n",
        "params = {'dim': (64,64),\n",
        "          'batch_size': 1,\n",
        "          'shuffle': True}\n",
        "training_generator = VideoFrameGenerator(train_ID, **params)\n",
        "validation_generator = VideoFrameGenerator([train_ID[0]], **params)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGncKImrPnt0"
      },
      "source": [
        "\n",
        "# index is the number of folders containing videos\n",
        "def get_train_data(folder_index , train = True , valid = True ) : \n",
        "    x = np.array([]).reshape(0,64,64,3)\n",
        "    y = np.array([]).reshape(0,) \n",
        "    if train : \n",
        "      x ,y = training_generator.__getitem__(folder_index)\n",
        "    if valid : \n",
        "      x ,y = validation_generator.__getitem__(folder_index)\n",
        "    return x,y\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZdb5LCYI4PY"
      },
      "source": [
        "#next step is to collect all the videos in one folder and take the first character of their name which is the label \n",
        "import numpy as np\n",
        "import keras\n",
        "a = np.array([]).reshape(0,64,64,3)\n",
        "b = np.array([]).reshape(0,)\n",
        "#path to video's folder\n",
        "path = '/content/gdrive/MyDrive/variables/Fold2_part2'\n",
        "class Frame_Generator(data_utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self,nb_iteration, batch_size=1, dim=(64,64), shuffle=True , COUNTER = 0 ,folder_index = 0,  train = True , Frame_train = np.array([]).reshape(0,64,64,3),label_train = np.array([]).reshape(0,) ):\n",
        "        'Initialization'\n",
        "        self.batch_size = batch_size\n",
        "        self.nb_iteration = nb_iteration  \n",
        "        self.shuffle = shuffle\n",
        "        self.dim = dim\n",
        "        self.train = train \n",
        "        self.folder_index = folder_index\n",
        "        self.COUNTER =  0\n",
        "        self.Frame_train = Frame_train\n",
        "        self.label_train = label_train\n",
        "        self.on_epoch_end()\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.nb_iteration) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        # indexes = np.arange(6000)\n",
        "        # Find list of IDs\n",
        "        frames_index = [self.nb_iteration[k] for k in indexes]\n",
        "        #list_IDs_temp = [20]\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(frames_index)\n",
        "\n",
        "        return X , y \n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.nb_iteration))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, frames_index):\n",
        "        global a \n",
        "        global b\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        #X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        #y = np.empty((self.batch_size), dtype=int)\n",
        "        if self.COUNTER % 300 == 0 : \n",
        "          #self.Frame_train ,self.label_train = get_train_data(self.folder_index , train = self.train , valid = self.valid)\n",
        "          self.Frame_train ,self.label_train = gen_frames(self.folder_index , train = self.train)\n",
        "          a = self.Frame_train\n",
        "          b = self.label_train\n",
        "          self.folder_index += 1\n",
        "          if self.folder_index == 29 : \n",
        "            self.folder_index = 0\n",
        "          self.COUNTER = 1 \n",
        "          return self.Frame_train[0:100], self.label_train[0:100]\n",
        "        else :\n",
        "          self.Frame_train = a[self.COUNTER*100:(self.COUNTER*100)+100]\n",
        "          self.label_train = b[self.COUNTER*100:(self.COUNTER*100)+100] \n",
        "          self.COUNTER += 1\n",
        "          return self.Frame_train, self.label_train\n",
        "        \n",
        "        "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Irs7iFwmazJ"
      },
      "source": [
        "# Parameters\n",
        "nb_iteration = np.arange(8400)\n",
        "train_params = {'dim': (64,64),\n",
        "          'batch_size': 1,\n",
        "          'shuffle': True,\n",
        "          'train':True}\n",
        "valid_params = {'dim': (64,64),\n",
        "          'batch_size': 1,\n",
        "          'shuffle': True,\n",
        "          'train':False}\n",
        "train_frames_generator = Frame_Generator(nb_iteration, **train_params)\n",
        "valid_frame_generator = Frame_Generator(np.arange(300), **valid_params)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2RmVIqC-6My",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9d06ec9-5778-4b9c-d00d-36ac0e2c6d8b"
      },
      "source": [
        "vgg16 = VGG16( include_top=False, input_shape = (64,64, 3) , weights = 'imagenet' )\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL_kUd51-9E6"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "for layer in vgg16.layers[:-1]: # this is where I changed your code\n",
        "    model.add(layer)    \n",
        "# Freeze the layers \n",
        "#for layer in model.layers:\n",
        "#    layer.trainable = False"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8CuTNl--_4S"
      },
      "source": [
        "model.add(Flatten())\n",
        "model.add(Dense(11, activation='softmax'))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23E83UnK_B7e",
        "outputId": "b46d8020-251f-42a0-e6b7-b30bc54177b2"
      },
      "source": [
        "model.build((0,64,64,3))\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 11)                90123     \n",
            "=================================================================\n",
            "Total params: 14,804,811\n",
            "Trainable params: 14,804,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMN_FQSJ_ElF"
      },
      "source": [
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "model.compile(optimizer = opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7jKkI1f_IPo",
        "outputId": "4110c80e-eb4e-473e-d8a6-82d6a91b58a7"
      },
      "source": [
        "history = model.fit(train_frames_generator,validation_data = valid_frame_generator ,  epochs = 5  )\n",
        "#, validation_data=valid_frame_generator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "8399/8400 [============================>.] - ETA: 1s - loss: 0.0397 - accuracy: 0.9926"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0CMwQaz_lko"
      },
      "source": [
        " model.save('/content/gdrive/MyDrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "panfjDhjZkxH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
